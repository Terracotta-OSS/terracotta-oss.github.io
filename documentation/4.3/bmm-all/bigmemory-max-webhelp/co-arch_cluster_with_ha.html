<!DOCTYPE html ><html xml:lang="en" lang="en" xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html;charset=utf-8"><meta http-equiv="Content-Style-Type" content="text/css"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><meta http-equiv="X-UA-Compatible" content="IE=edge"><title>Terracotta Cluster with High Availability</title><link rel="Prev" href="co-arch_frs_disk_compaction.html" title="Previous"><link rel="Next" href="co-arch_cluster_failover_tuning.html" title="Next"><link rel="StyleSheet" href="css/aaa_bigmem_max_all.css" type="text/css" media="all"><link rel="StyleSheet" href="css/skin.css" type="text/css" media="all"><link rel="StyleSheet" href="css/social.css" type="text/css" media="all"><link rel="StyleSheet" href="css/webworks.css" type="text/css" media="all"><!--[if IE 7]><link rel="StyleSheet" href="css/aaa_bigmem_max_all_IE7.css" type="text/css" media="all"><![endif]--><link rel="StyleSheet" href="css/print.css" type="text/css" media="print"><script type="text/javascript">
    'use strict';

    var redirect_url, page_hash;

    if (window === window.top) {
        // Redirect
        //
        redirect_url = "../index.html#page/bigmemory-max-webhelp/co-arch_cluster_with_ha.html";
        if (window.document.location.hash.length > 1) {
            // Sanitize and append it
            //
            page_hash = window.document.location.hash.substring(1);
            page_hash = page_hash.replace(/[\\><:;"]|%5C|%3C|%3E|%3A|%3B|%22/gi, '');
            redirect_url += '#' + page_hash;
        }
        window.document.location.replace(redirect_url);
    }
</script><script type="text/javascript" src="scripts/common.js"></script><script type="text/javascript" src="scripts/page.js"></script><script type="text/javascript" src="scripts/search-client.js"></script><script type="text/javascript" src="scripts/unidata.js"></script><script type="text/javascript" src="scripts/unibreak.js"></script></head><body id="psQOBi_002fgPASZ3pqRaSr8Taw" class="ww_skin_page_body" onload="Page.OnLoad('../index.html#page/bigmemory-max-webhelp/co-arch_cluster_with_ha.html');"><header id="wwconnect_header"><div class="ww_skin_breadcrumbs"><span class="ww_skin_breadcrumbs_parent"><a href="../bigmemory-max-webhelp/to-title_product_documentation.html#wwconnect_header">Product Documentation</a></span><span class="ww_skin_breadcrumbs_divider"> : </span><span class="ww_skin_breadcrumbs_parent"><a href="../bigmemory-max-webhelp/to-title_bigmemory_max_admin_guide.html#wwconnect_header">BigMemory Max Administrator Guide</a></span><span class="ww_skin_breadcrumbs_divider"> : </span><span class="ww_skin_breadcrumbs_parent"><a href="../bigmemory-max-webhelp/to-arch_architecture.html#wwconnect_header">Terracotta Server Array Architecture</a></span><span class="ww_skin_breadcrumbs_divider"> : </span><span class="ww_skin_breadcrumbs_current">Terracotta Cluster with High Availability</span></div><div class="ww_skin_page_toolbar"></div></header><div id="ww3_17_12_9_12_1" class="Heading_3">Terracotta Cluster with High Availability</div><div id="ww3_17_12_9_12_3_2" class="Body"><span class="inlinetitle"> Persistence: Yes | Failover: Yes | Scale: No</span></div><div id="ww3_17_12_9_12_3_4" class="Body">The example above presents a reliable but <span class="emphasis">not</span> highly available cluster. If the server fails, the cluster fails. There is no redundancy to provide failover. Adding a mirror server adds availability because the mirror serves as a "hot standby" ready to take over for the active server in case of a failure.</div><img class="Default" src="../bigmemory-max-webhelp/images/server_array_ap.png" style="display: inline; float: none" alt=""><div id="ww3_17_12_9_12_3_8" class="Body">In this array, if the active Terracotta server instance fails, then the mirror instantly takes over and the cluster continues functioning. No data is lost.</div><div id="ww3_17_12_9_12_3_10" class="Body">The following Terracotta configuration file demonstrates how to configure this two-server array:</div><div id="ww3_17_12_9_12_3_12" class="Preformatted">&lt;?xml version="1.0" encoding="UTF-8" ?&gt;<br>&lt;tc:tc-config xmlns:tc="http://www.terracotta.org/config"<br> xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"<br>xsi:schemaLocation="http://www.terracotta.org/schema/terracotta-9.xsd"&gt;<br> &lt;servers&gt;<br>   &lt;server name="Server1"&gt;<br>     &lt;data&gt;/opt/terracotta/server1-data&lt;/data&gt;<br>     &lt;tsa-port&gt;9510&lt;/tsa-port&gt;<br>     &lt;jmx-port&gt;9520&lt;/jmx-port&gt;<br>     &lt;tsa-group-port&gt;9530&lt;/tsa-group-port&gt;<br>     &lt;management-port&gt;9540&lt;/management-port&gt;<br>     &lt;dataStorage size="4g"&gt;<br>        &lt;offheap size="4g"/&gt; <br>     &lt;/dataStorage&gt;<br>   &lt;/server&gt;<br>   &lt;server name="Server2"&gt;<br>     &lt;data&gt;/opt/terracotta/server2-data&lt;/data&gt;<br>     &lt;tsa-port&gt;9510&lt;/tsa-port&gt;<br>     &lt;jmx-port&gt;9520&lt;/jmx-port&gt;<br>     &lt;tsa-group-port&gt;9530&lt;/tsa-group-port&gt;<br>     &lt;management-port&gt;9540&lt;/management-port&gt;<br>     &lt;dataStorage size="4g"&gt;<br>        &lt;offheap size="4g"/&gt; <br>     &lt;/dataStorage&gt;<br>   &lt;/server&gt;<br>   &lt;restartable enabled="true"/&gt;<br>   &lt;client-reconnect-window&gt;120&lt;/client-reconnect-window&gt;<br> &lt;/servers&gt;<br> ...<br>&lt;/tc:tc-config&gt;</div><div id="ww3_17_12_9_12_3_14" class="Body">You can add more mirror servers to this configuration by adding more <span class="codeph">&lt;server&gt;</span> sections. However, a performance overhead may become evident when adding more mirror servers due to the load placed on the active server by having to synchronize with each mirror.</div><div class="ww_skin_page_overflow"><table class="note1" summary=""><tr><td class="Table_Cell" style="padding-right: 6px; vertical-align: top"><div id="ww3_17_12_9_12_3_16_1_3_1_1_1" class="Note"><span style="font-weight: bold">Note:  </span>&nbsp;</div></td><td class="Table_Cell" style="padding-right: 6px; vertical-align: top"><div id="ww3_17_12_9_12_3_16_1_3_1_2" class="Table_Cell">Terracotta server instances must not share data directories. Each server's <span class="codeph">&lt;data&gt;</span> element should point to a different and preferably local data directory.</div></td></tr></table></div><div id="ww3_17_12_9_12_3_18_2" class="Section_Title">Starting the Servers</div><div id="ww3_17_12_9_12_3_18_4" class="Body">How server instances behave at startup depends on when in the life of the cluster they are started.</div><div id="ww3_17_12_9_12_3_18_6" class="Body">In a single-server configuration, when the server is started it performs a startup routine and then is ready to run the cluster (ACTIVE status). If multiple server instances are started at the same time, one is elected the active server (ACTIVE-COORDINATOR status) while the others serve as mirrors (PASSIVE-STANDBY status). The election is recorded in the servers' logs.</div><div id="ww3_17_12_9_12_3_18_8" class="Body">If a server instance is started while an active server instance is already running, it syncs up state from the active server instance before becoming a mirror. The active and mirror servers must always be synchronized, allowing the mirror server to mirror the state of the active. The mirror server goes through the following states:</div><div id="ww3_17_12_9_12_3_18_10_2_2" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>1. </span></span><span class="inlinetitle">PASSIVE-UNINITIALIZED</span> - The mirror is beginning its startup sequence and is <span class="emphasis">not</span> ready to perform failover should the active fail or be shut down. The server's status light in the Terracotta Management Console (TMC) switches from red to orange.</div><div id="ww3_17_12_9_12_3_18_10_2_4" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>2. </span></span><span class="inlinetitle">INITIALIZING</span> - The mirror is synchronizing state with the active and is <span class="emphasis">not</span> ready to perform failover should the active fail or be shut down. The server's status light in the TMC is orange.</div><div id="ww3_17_12_9_12_3_18_10_2_6" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>3. </span></span><span class="inlinetitle">PASSIVE-STANDBY</span> - The mirror is synchronized and is ready to perform failover should the active server fail or be shut down. The server's status light in the TMC switches from orange to cyan.</div><div id="ww3_17_12_9_12_3_18_12" class="Body">The active server instance carries the load of sending state to the mirror during the synchronization process. The time taken to synchronize is dependent on the amount of clustered data and on the current load on the cluster. The active server instance and mirrors should be run on similarly configured machines for better throughput, and should be started together to avoid unnecessary sync ups.</div><div id="ww3_17_12_9_12_3_18_14" class="Body">The sequence in which servers startup does not affect data. Even if a former mirror server is initialized before the former active server, the mirror server's data is not erased. In the event that a mirror server went offline while the active server was still up, then when the mirror server returns, it remembers that it was in the mirror role. Even if the active server is offline at that point, the mirror server does not try to become the active. It waits until the active server returns, and clients are blocked from updating their data. When the active returns, it will restart the mirror. The mirror's data objects and indices are then moved to the dirty-objectdb-backup directory, and the active syncs its data with the mirror.</div><div id="ww3_17_12_9_12_3_20_2" class="Section_Title">Failover</div><div id="ww3_17_12_9_12_3_20_4" class="Body">If the active server instance fails and two or more mirror server instances are available, an election determines the new active. Successful failover to a new active takes place only if at least one mirror server is fully synchronized with the failed active server; successful client failover (migration to the new active) can happen only if the server failover is successful. Shutting down the active server before a fully-synchronized mirror is available can result in a cluster-wide failure.</div><div id="ww3_17_12_9_12_3_20_6" class="Body">If the <span class="codeph">dataStorage</span> and/or <span class="codeph">offheap</span> size on the mirror server is smaller than on the active server, then the mirror server will fail to start and the user will be alerted that the configuration is invalid. If there are multiple mirrors with differing amounts of storage configured, then the passive with the smallest <span class="codeph">dataStorage</span> and <span class="codeph">offheap</span> sizes (that are still greater than or equal to the active's <span class="codeph">dataStorage</span> and <span class="codeph">offheap</span> sizes) will be elected to be the new active.</div><div class="ww_skin_page_overflow"><table class="note1" summary=""><tr><td class="Table_Cell" style="padding-right: 6px; vertical-align: top"><div id="ww3_17_12_9_12_3_20_8_1_3_1_1_1" class="tip"><span style="font-weight: bold">Tip:  </span>&nbsp;</div></td><td class="Table_Cell" style="padding-right: 6px; vertical-align: top"><div id="ww3_17_12_9_12_3_20_8_1_3_1_2" class="Table_Cell">Hot-Swapping Mirrors - A mirror can be hot-swapped if the replacement matches the original mirror's &lt;server&gt; block in the Terracotta configuration. For example, the new mirror should use the same host name or IP address configured for the original mirror. For information about swapping in a mirror with a different configuration, refer to <span class="xref"><a href="../bigmemory-max-webhelp/to-top_changing_topology_of_a_live_cluster.html#wwconnect_header" title="Changing Topology of a Live Cluster">Changing Topology of a Live Cluster</a></span>. </div></td></tr></table></div><div id="ww3_17_12_9_12_3_20_10" class="Body">Terracotta server instances acting as mirrors can run either in restartable mode or non-persistent mode. If a server instance running in restartable mode goes down, and a mirror takes over, the crashed server's data directory is cleared before it is restarted and allowed to rejoin the cluster. Removing the data is necessary because the cluster state could have changed since the crash. During startup, the restarted server's new state is synchronized from the new active server instance.</div><div id="ww3_17_12_9_12_3_20_12" class="Body">If both servers are down, and clustered data is persisted, the last server to be active will automatically be started first to avoid errors and data loss.</div><div id="ww3_17_12_9_12_3_20_14" class="Body">In setups where data is not persisted, meaning that restartable mode is not enabled, then no data is saved and either server can be started first.</div><div class="ww_skin_page_overflow"><table class="note1" summary=""><tr><td class="Table_Cell" style="padding-right: 6px; vertical-align: top"><div id="ww3_17_12_9_12_3_20_16_1_3_1_1_1" class="Note"><span style="font-weight: bold">Note:  </span>&nbsp;</div></td><td class="Table_Cell" style="padding-right: 6px; vertical-align: top"><div id="ww3_17_12_9_12_3_20_16_1_3_1_2" class="Table_Cell">Under certain circumstances pertaining to server restarts, the data directory should be manually cleared. For more information, refer to <span class="xref"><a href="../bigmemory-max-webhelp/to-clear_clearing_data_from_a_server.html#wwconnect_header" title="Clearing Data from a Terracotta Server">Clearing Data from a Terracotta Server</a></span> </div></td></tr></table></div><div id="ww3_17_12_9_12_3_22_2" class="Section_Title">A Safe Failover Procedure</div><div id="ww3_17_12_9_12_3_22_4" class="Body">To safely migrate clients to a mirror server without stopping the cluster, follow these steps:</div><div id="ww3_17_12_9_12_3_22_6_2_2_3" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>1. </span></span>If it is not already running, start the mirror server using the start-tc-server script. The mirror server must already be configured in the Terracotta configuration file.</div><div id="ww3_17_12_9_12_3_22_6_2_4_3" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>2. </span></span>Ensure that the mirror server is ready for failover (PASSIVE-STANDBY status). In the TMC, the status light will be cyan.</div><div id="ww3_17_12_9_12_3_22_6_2_6_3" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>3. </span></span>Shut down the active server using the stop-tc-server script.</div><div class="ww_skin_page_overflow"><table class="note2" summary=""><tr><td class="Table_Cell" style="padding-right: 6px; vertical-align: top"><div id="ww3_17_12_9_12_3_22_6_2_6_5_1_3_1_2_1" class="Note"><span style="font-weight: bold">Note:  </span>&nbsp;</div></td><td class="Table_Cell" style="padding-right: 6px; vertical-align: top"><div id="ww3_17_12_9_12_3_22_6_2_6_5_1_3_1_3" class="Table_Cell">If the script detects that the mirror server in STANDBY state isn't reachable, it issues a warning and fails to shut down the active server. If failover is not a concern, you can override this behavior with the <span class="codeph">--force</span> flag.</div></td></tr></table></div><div id="ww3_17_12_9_12_3_22_6_2_6_7" class="Numbered_1_Continued">Clients will connect to the new active server.</div><div id="ww3_17_12_9_12_3_22_6_2_8_3" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>4. </span></span>Restart any clients that fail to reconnect to the new active server within the configured reconnection window.</div><div id="ww3_17_12_9_12_3_22_8" class="Body">The previously active server can now rejoin the cluster as a mirror server. If restartable mode had been enabled, its data is first removed and then the current data is read in from the now active server.</div><div id="ww3_17_12_9_12_3_24_2" class="Section_Title">A Safe Cluster Shutdown Procedure</div><div id="ww3_17_12_9_12_3_24_4" class="Body">A safe cluster shutdown should follow these steps:</div><div id="ww3_17_12_9_12_3_24_6_2_3" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>1. </span></span>Shut down the mirror servers using the stop-tc-server script.</div><div id="ww3_17_12_9_12_3_24_6_4_3" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>2. </span></span>Shut down the clients. The Terracotta client will shut down when you shut down your application.</div><div id="ww3_17_12_9_12_3_24_6_6_3" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>3. </span></span>Shut down the active server using the stop-tc-server script.</div><div id="ww3_17_12_9_12_3_24_8" class="Body">To restart the cluster, first start the server that was last active. If clustered data is not persisted, any of the servers could be started first as no data conflicts can take place.</div><div id="ww3_17_12_9_12_3_26_2" class="Section_Title">Split Brain Scenario</div><div id="ww3_17_12_9_12_3_26_4" class="Body">In a Terracotta cluster, "split brain" refers to a scenario where two servers assume the role of active server (ACTIVE-COORDINATOR status). This can occur during a network problem that disconnects the active and mirror servers, causing the mirror to both become an active server and open a reconnection window for clients (&lt;client-reconnect-window&gt;).</div><div id="ww3_17_12_9_12_3_26_6" class="Body">If the connection between the two servers is never restored, then two independent clusters are in operation. This is a split-brain situation. However, if the connection is restored, one of the following scenarios results:</div><div id="ww3_17_12_9_12_3_26_8_2_2_3" class="List_1"><span class="WebWorks_Number" style="width: 18pt"><span><img src="bullet.gif" alt="*" border="0" width="10" height="10"></span></span>No clients connect to the new active server - The original active server "zaps" the new active server, causing it to restart, wipe its database, and synchronize again as a mirror.</div><div id="ww3_17_12_9_12_3_26_8_2_4_3" class="List_1"><span class="WebWorks_Number" style="width: 18pt"><span><img src="bullet.gif" alt="*" border="0" width="10" height="10"></span></span>A minority of clients connect to the new active server - The original active server starts a reconnect timeout for the clients that it loses, while zapping the new active server. The new active restarts, wipes its database, and synchronizes again as a mirror. Clients that defected to the new active attempt to reconnect to the original active, but if they do not succeed within the parameters set by that server, they must be restarted.</div><div id="ww3_17_12_9_12_3_26_8_2_6_3" class="List_1"><span class="WebWorks_Number" style="width: 18pt"><span><img src="bullet.gif" alt="*" border="0" width="10" height="10"></span></span>A majority of clients connects to the new active server - The new active server "zaps" the original active server. The original active restarts, wipes its database, and synchronizes again as a mirror. Clients that do not connect to the new active within its configured reconnection window must be restarted.</div><div id="ww3_17_12_9_12_3_26_8_2_8_3" class="List_1"><span class="WebWorks_Number" style="width: 18pt"><span><img src="bullet.gif" alt="*" border="0" width="10" height="10"></span></span>An equal number of clients connect to the new active server - In this unlikely event, exactly one half of the original active server's clients connect to the new active server. The servers must now attempt to determine which of them holds the latest transactions (or has the freshest data). The winner zaps the loser, and clients behave as noted above, depending on which server remains active. Manual shutdown of one of the servers may become necessary if a timely resolution does not occur.</div><div id="ww3_17_12_9_12_3_26_10" class="Body">In the case of split-brain occurrences it is imperative to confirm the integrity of shared data after such an event.</div><div class="ww_skin_page_overflow"><table class="note1" summary=""><tr><td class="Table_Cell" style="padding-right: 6px; vertical-align: top"><div id="ww3_17_12_9_12_3_26_12_1_3_1_1_1" class="Note"><span style="font-weight: bold">Note:  </span>&nbsp;</div></td><td class="Table_Cell" style="padding-right: 6px; vertical-align: top"><div id="ww3_17_12_9_12_3_26_12_1_3_1_2" class="Table_Cell">Under certain circumstances pertaining to server restarts, the data directory should be manually cleared. For more information, refer to <span class="xref"><a href="../bigmemory-max-webhelp/to-clear_clearing_data_from_a_server.html#wwconnect_header" title="Clearing Data from a Terracotta Server">Clearing Data from a Terracotta Server</a></span>. </div></td></tr></table></div><footer><!-- Related Topics --><!--                --><!-- Back to Top --><!--             --><!-- Disqus --><!--        --><!-- Google Translation --><!--                    --><br></footer><div><div style="font-family: Arial, Verdana, Helvetica, Sans-Serif; font-size: 11px; margin-top: 20px; margin-bottom: 20px;"><span class="xref"><a href="http://documentation.softwareag.com/legal/" target="external_window">Copyright Â© <span>2010</span><span>-2016</span><span></span><span></span> Software AG, Darmstadt, Germany</a></span>.</div><hr></div><div style="font-family: Arial, Verdana, Helvetica, Sans-Serif; font-size: 13px; font-weight: bold; margin-top: 20px;"><span><img style="vertical-align:middle" src="../connect/terracotta_online.png" alt="Product Logo"><a href="https://empower.softwareag.com/ContactSupport/default.asp" target="_blank">Contact&nbsp;Support</a>
         &nbsp;&nbsp;|&nbsp;&nbsp;
       <a href="http://www.softwareag.com/corporate/community/default.asp" target="_blank">Community</a>
         &nbsp;&nbsp;|&nbsp;&nbsp;
       <a href="mailto://documentation@softwareag.com" target="_blank">Feedback&nbsp;&nbsp;</a></span></div></body></html>