<!DOCTYPE html ><html xml:lang="en" lang="en" xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html;charset=utf-8"><meta http-equiv="Content-Style-Type" content="text/css"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><meta http-equiv="X-UA-Compatible" content="IE=edge"><title>Fast Restart (FRS) Disk Compaction Strategies</title><link rel="Prev" href="co-arch_cluster_with_reliability.html" title="Previous"><link rel="Next" href="co-arch_cluster_with_ha.html" title="Next"><link rel="StyleSheet" href="css/aaa_bigmem_max_all.css" type="text/css" media="all"><link rel="StyleSheet" href="css/skin.css" type="text/css" media="all"><link rel="StyleSheet" href="css/social.css" type="text/css" media="all"><link rel="StyleSheet" href="css/webworks.css" type="text/css" media="all"><!--[if IE 7]><link rel="StyleSheet" href="css/aaa_bigmem_max_all_IE7.css" type="text/css" media="all"><![endif]--><link rel="StyleSheet" href="css/print.css" type="text/css" media="print"><script type="text/javascript">
    'use strict';

    var redirect_url, page_hash;

    if (window === window.top) {
        // Redirect
        //
        redirect_url = "../index.html#page/bigmemory-max-webhelp/co-arch_frs_disk_compaction.html";
        if (window.document.location.hash.length > 1) {
            // Sanitize and append it
            //
            page_hash = window.document.location.hash.substring(1);
            page_hash = page_hash.replace(/[\\><:;"]|%5C|%3C|%3E|%3A|%3B|%22/gi, '');
            redirect_url += '#' + page_hash;
        }
        window.document.location.replace(redirect_url);
    }
</script><script type="text/javascript" src="scripts/common.js"></script><script type="text/javascript" src="scripts/page.js"></script><script type="text/javascript" src="scripts/search-client.js"></script><script type="text/javascript" src="scripts/unidata.js"></script><script type="text/javascript" src="scripts/unibreak.js"></script></head><body id="pwH2tvF_002fZX9jsWSgs20e5OA" class="ww_skin_page_body" onload="Page.OnLoad('../index.html#page/bigmemory-max-webhelp/co-arch_frs_disk_compaction.html');"><header id="wwconnect_header"><div class="ww_skin_breadcrumbs"><span class="ww_skin_breadcrumbs_parent"><a href="../bigmemory-max-webhelp/to-title_product_documentation.html#wwconnect_header">Product Documentation</a></span><span class="ww_skin_breadcrumbs_divider"> : </span><span class="ww_skin_breadcrumbs_parent"><a href="../bigmemory-max-webhelp/to-title_bigmemory_max_admin_guide.html#wwconnect_header">BigMemory Max Administrator Guide</a></span><span class="ww_skin_breadcrumbs_divider"> : </span><span class="ww_skin_breadcrumbs_parent"><a href="../bigmemory-max-webhelp/to-arch_architecture.html#wwconnect_header">Terracotta Server Array Architecture</a></span><span class="ww_skin_breadcrumbs_divider"> : </span><span class="ww_skin_breadcrumbs_current">Fast Restart (FRS) Disk Compaction Strategies</span></div><div class="ww_skin_page_toolbar"></div></header><div id="ww3_17_12_9_10_1" class="Heading_3">Fast Restart (FRS) Disk Compaction Strategies</div><div id="ww3_17_12_9_10_3_2" class="Body">Since Terracotta is a product intended to maximize performance, a performance-focused "append-only-log" architecture is used for the FRS disk persistence technology.</div><div id="ww3_17_12_9_10_3_4" class="Body">Terracotta supports the following two compaction strategies:</div><div id="ww3_17_12_9_10_3_6_2" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>1. </span></span>Performance Based Compaction Policy - Favors predictable performance at the expense of unpredictable disk storage space requirements. This is the default strategy.</div><div id="ww3_17_12_9_10_3_6_4" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>2. </span></span>Size Based Compaction Policy - Favors predictable disk storage space requirements at the expense of unpredictable performance.</div><div id="ww3_17_12_9_10_3_8_2" class="Section_Title">Overview of Behavior</div><div id="ww3_17_12_9_10_3_8_4" class="Body">The following process describes in general what you can expect to observe occurring on the file system in the configured &lt;data&gt; folder. This process is the same, regardless of which of the two compaction strategies you use:</div><div id="ww3_17_12_9_10_3_8_6_2" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>1. </span></span>Data is added to Terracotta cache(s).</div><div id="ww3_17_12_9_10_3_8_6_4" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>2. </span></span>An FRS file is created with a file name pattern similar to "seg&lt;nnnn&gt;.frs", where &lt;nnnn&gt; is a number. This file receives all current data writes.</div><div id="ww3_17_12_9_10_3_8_6_6" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>3. </span></span>As data is further added to Terracotta cache(s), the current FRS file will grow in size.</div><div id="ww3_17_12_9_10_3_8_6_8" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>4. </span></span>Once the current FRS file grows to some predetermined size, the file is closed.</div><div id="ww3_17_12_9_10_3_8_6_10" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>5. </span></span>Repeat from Step 2 above, where the file name's &lt;nnnn&gt; is incremented by 1.</div><div id="ww3_17_12_9_10_3_8_8" class="Body">It is important to note from the above process that any given FRS file only grows in size to some limit before it is closed and another file is created. This leads to increasing disk consumption.</div><div id="ww3_17_12_9_10_3_8_10" class="Body">Based on internal product heuristics, Terracotta will periodically try to "copy" living/valid data into newer FRS files. Once all the cached data in an older FRS file is either "dead" (i.e. the "time to live" has expired) or has been successfully copied to a newer FRS file, then that older FRS file will be deleted in its entirety and its associated disk space will be reclaimed.</div><div id="ww3_17_12_9_10_3_8_12" class="Body">In short, disk usage will accumulate to some amount, then some storage space will be "freed", and the process will repeat itself.</div><div class="ww_skin_page_overflow"><table class="note1" summary=""><tr><td class="Table_Cell" style="padding-right: 6px; vertical-align: top"><div id="ww3_17_12_9_10_3_8_14_1_3_1_1_1" class="Note"><span style="font-weight: bold">Note:  </span>&nbsp;</div></td><td class="Table_Cell" style="padding-right: 6px; vertical-align: top"><div id="ww3_17_12_9_10_3_8_14_1_3_1_2" class="Table_Cell">It is very important to determine upper-bound used-disk space and ensure the environment always has enough free storage capacity to safely function. We recommend determining this upper-bound, then pad this figure by approximately 20% or more (to accommodate variations in usage), and set that as the "minimum required free disk space" for successful product operation.</div></td></tr></table></div><div id="ww3_17_12_9_10_3_10_2" class="Section_Title">Performance Based Compaction Policy (Default)</div><div id="ww3_17_12_9_10_3_10_4" class="Body">As noted above, the Performance Based Compaction Policy is the default compaction strategy because it provides the fastest predictable performance which is of paramount concern to "Big Data" users. This strategy frees up disk space associated with data which is either redundant or has been removed from cache. This strategy provides fast, predictable performance at the cost of large (and comparatively cheap) disk storage space. Put another way, this compaction strategy intentionally sacrifices disk space to provide maximal disk performance.</div><div id="ww3_17_12_9_10_3_10_6" class="Body">The amount of disk storage space that is required to successfully operate Terracotta when using this compaction strategy is wholly dependent upon a variety of use-case specific factors (such as data size, data volume, configured data lifetime, access patterns, etc.) which cannot reasonably be "guessed at" to determine the minimal FRS disk space requirements for a deployment. The only way to know how much disk space will be required for successful operation is to test the real use-case, under real load, and monitor the resulting disk usage.</div><div id="ww3_17_12_9_10_3_10_8" class="Body">The following are some observed real world examples. Please note that every use-case is different and that any particular usage could yield wildly different results; the following is intended to be used for illustrative purposes only to show what is possible as a normally expected disk usage.</div><div id="ww3_17_12_9_10_3_10_10" class="inlinetitle"><span class="inlinetitle">Scenario: 50 MB Real Data</span></div><div id="ww3_17_12_9_10_3_10_12" class="Body">FRS was designed to efficiently manage Big Data use-cases; the side effect is that small data volumes typically exhibit a high "relative" disk usage cost.</div><div id="ww3_17_12_9_10_3_10_14" class="Body">With this use-case, there are approximately 50 MB of real data which is completely reloaded/refreshed every 24 hours from the backing data store. Based on the data lifetime requirements and access patterns the following behavior might result:</div><div id="ww3_17_12_9_10_3_10_16_2" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>1. </span></span>Each FRS file slowly grows in size to approximately 512 MB before another file is created.</div><div id="ww3_17_12_9_10_3_10_16_4" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>2. </span></span>The number of FRS files accumulates to an average of 14 FRS files (each at ~512 MB) before the configured data life-cycle coupled with the data access patterns allows FRS files to be freed.</div><div id="ww3_17_12_9_10_3_10_16_6" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>3. </span></span>All "old" FRS files are deleted except the most recent 3 FRS files.</div><div id="ww3_17_12_9_10_3_10_18" class="Body">Under normal operation, FRS disk usage could grow up to approximately 7.1 GB (14 files of 512 MB each) before 11 FRS files would be deleted (freeing about 5.6 GB) leaving 1.5 GB used on disk. Then the process would repeat, where the 1.5 GB grows to 7.1 GB, at which point 5.6 GB would be freed again. This pattern would repeat over the lifetime of this customer's deployment.</div><div id="ww3_17_12_9_10_3_10_20" class="inlinetitle"><span class="inlinetitle">Scenario: 11 GB Real Data </span></div><div id="ww3_17_12_9_10_3_10_22" class="Body">With this use-case, there are approximately 11 GB of real data which is completely reloaded/refreshed every 24 hours from the backing data store. If the used disk-space is observed to peak at approximately 50 GB, we would recommend ensuring that there are 60 GB of free space (50 GB padded by 20%) dedicated to Terracotta data storage.</div><div id="ww3_17_12_9_10_3_10_24" class="inlinetitle"><span class="inlinetitle"> Scenario: 760 GB Real Data (4 Stripe Terracotta Server Array) </span></div><div id="ww3_17_12_9_10_3_10_26" class="Body">With this use-case, there are approximately 760 GB of real data distributed across 4 Terracotta Servers, with each Terracotta Server containing approximately 190 GB of that data. The majority of the time, this deployment is used for a read-heavy "pure caching" use-case which results in FRS disk usage peaking at about 500 GB on each Terracotta Server. For this usage, it should be safe to ensure that there is 600 GB (500 GB + 20%) of free disk storage capacity reserved for Terracotta usage.</div><div id="ww3_17_12_9_10_3_10_28" class="Body">However, once every 2 weeks, a write-heavy "data-reconciliation" process is executed which updates the entire 760 GB data-set (~190 GB per server). Due to the access patterns required to perform the data reconciliation during this bi-weekly process, FRS disk usage temporarily peaks during this window of time on each Terracotta Server at about 2000 GB (2 TB).</div><div id="ww3_17_12_9_10_3_10_30" class="Body">In summary, each Terracotta Server:</div><div id="ww3_17_12_9_10_3_10_32_2" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>1. </span></span>Stores approximately 190 GB of data.</div><div id="ww3_17_12_9_10_3_10_32_4" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>2. </span></span>Under normal operation requires at least 500 GB of free disk capacity.</div><div id="ww3_17_12_9_10_3_10_32_6" class="Numbered_1"><span class="WebWorks_Number" style="width: 18pt"><span>3. </span></span>Only during the bi-weekly data reconciliation operation, the minimum free disk space requirement grows from the normal 500 GB to 2 TB.</div><div id="ww3_17_12_9_10_3_10_34" class="Body">Based on the observed application requirements, it is recommended to allocate at least 2.4 TB (2 TB + 20%) of free disk storage capacity to safely operate during this bi-weekly process.</div><div id="ww3_17_12_9_10_3_12_2" class="Section_Title">Optional Compaction Strategy (Size Based Compaction Policy)</div><div id="ww3_17_12_9_10_3_12_4" class="Body">If constraining FRS on-disk usage is more important than performance (i.e. predictable performance is not important), then the "Size Based Compaction Policy" can be used instead.</div><div id="ww3_17_12_9_10_3_12_6" class="Body">This optional compaction strategy is configured in the Terracotta Server's "tc-config.xml" by adding a new "tc-property" to the "tc-properties" section as follows:</div><div id="ww3_17_12_9_10_3_12_8" class="Preformatted">&lt;tc-properties&gt;<br>    &lt;property name="l2.frs.compactor.policy" value="SizeBasedCompactionPolicy"/&gt;<br>&lt;/tc-properties&gt;</div><div id="ww3_17_12_9_10_3_12_10" class="Body">By default, this compaction strategy will attempt to constrain the on-disk size to approximately 2 times the overall data size but is influenced by the FRS "segment size".</div><div id="ww3_17_12_9_10_3_12_12" class="Body">The default FRS segment file size is 512 MB (53687092 bytes), but this can be further tuned by changing the value used the following "tc-property":</div><div id="ww3_17_12_9_10_3_12_14" class="Preformatted">&lt;property name="l2.frs.io.nio.segmentSize" value="53687092"/&gt;<br>&lt;!-- 512MB = 32 * 1024 * 1024 --&gt; <br></div><div id="ww3_17_12_9_10_3_12_16" class="Body">For small data sets, it might make sense to reduce the FRS segment file size relative to the amount of data being stored; such tuning will be an iterative process is dependent upon the data storage and access requirements of the application.</div><div id="ww3_17_12_9_10_3_12_18" class="inlinetitle"><span class="inlinetitle"> Configuration Example: 32 MB segment size</span></div><div id="ww3_17_12_9_10_3_12_20" class="Preformatted">&lt;tc-properties&gt;<br>    &lt;property name="l2.frs.compactor.policy" value="SizeBasedCompactionPolicy"/&gt;<br>    &lt;property name="l2.frs.io.nio.segmentSize" value="33554432"/&gt;  &lt;!-- 32MB = 32 * 1024 * 1024 --&gt;<br>&lt;/tc-properties&gt;</div><div id="ww3_17_12_9_10_3_12_22" class="inlinetitle"><span class="inlinetitle"> Configuration Example: 256 MB segment size</span></div><div id="ww3_17_12_9_10_3_12_24" class="Preformatted">&lt;tc-properties&gt;<br>    &lt;property name="l2.frs.compactor.policy" value="SizeBasedCompactionPolicy"/&gt;<br>    &lt;property name="l2.frs.io.nio.segmentSize" value="268435456"/&gt;  &lt;!-- 256MB = 256 * 1024 * 1024 --&gt;<br>&lt;/tc-properties&gt;</div><div id="ww3_17_12_9_10_3_12_26" class="inlinetitle"><span class="inlinetitle"> Configuration (Advanced)</span></div><div id="ww3_17_12_9_10_3_12_28" class="Body">The vast majority of use-cases should be successfully handled using the above options; what follows is included for completeness. These additional tuning parameters are only applicable when the Size Based Compaction Policy is being used and should be used with great caution.</div><div class="ww_skin_page_overflow"><table class="note1" summary=""><tr><td class="Table_Cell" style="padding-right: 6px; vertical-align: top"><div id="ww3_17_12_9_10_3_12_30_1_3_1_1_1" class="Note"><span style="font-weight: bold">Note:  </span>&nbsp;</div></td><td class="Table_Cell" style="padding-right: 6px; vertical-align: top"><div id="ww3_17_12_9_10_3_12_30_1_3_1_2" class="Table_Cell">The "value" of each parameter is expressed in percent as a fraction of 1.0 such that 100%=1.0, 85%=0.85, 50%=0.5, 5%=0.05, etc.</div></td></tr></table></div><div id="ww3_17_12_9_10_3_12_32" class="Body">The following property controls when to trigger/start the on-disk data compaction process. The formula used to determine the trigger threshold is INMEMORY_DATA / DISK_USED.</div><div id="ww3_17_12_9_10_3_12_34" class="Preformatted">&lt;!-- start compaction when in-memory size is 50% of what on-disk size is, <br>or in other words when disk is twice as much --&gt;<br>&lt;property name="l2.frs.compactor.sizeBased.threshold" value="0.50"/&gt;</div><div id="ww3_17_12_9_10_3_12_36" class="Body">The following property controls how much data should be compacted at a time. By default, the Size Based Compaction Policy will attempt to free 5% of the on-disk stored data.</div><div id="ww3_17_12_9_10_3_12_38" class="Preformatted">&lt;property name="l2.frs.compactor.sizeBased.amount" value="0.05"/&gt;</div><footer><!-- Related Topics --><!--                --><!-- Back to Top --><!--             --><!-- Disqus --><!--        --><!-- Google Translation --><!--                    --><br></footer><div><div style="font-family: Arial, Verdana, Helvetica, Sans-Serif; font-size: 11px; margin-top: 20px; margin-bottom: 20px;"><span class="xref"><a href="http://documentation.softwareag.com/legal/" target="external_window">Copyright Â© <span>2010</span><span>-2016</span><span></span><span></span> Software AG, Darmstadt, Germany</a></span>.</div><hr></div><div style="font-family: Arial, Verdana, Helvetica, Sans-Serif; font-size: 13px; font-weight: bold; margin-top: 20px;"><span><img style="vertical-align:middle" src="../connect/terracotta_online.png" alt="Product Logo"><a href="https://empower.softwareag.com/ContactSupport/default.asp" target="_blank">Contact&nbsp;Support</a>
         &nbsp;&nbsp;|&nbsp;&nbsp;
       <a href="http://www.softwareag.com/corporate/community/default.asp" target="_blank">Community</a>
         &nbsp;&nbsp;|&nbsp;&nbsp;
       <a href="mailto://documentation@softwareag.com" target="_blank">Feedback&nbsp;&nbsp;</a></span></div></body></html>